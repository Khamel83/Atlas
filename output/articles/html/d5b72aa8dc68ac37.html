<!DOCTYPE html>
<html>
<head>
    <title>In Continued Defense Of Effective Altruism</title>
    <meta charset="utf-8">
</head>
<body>
    <h1>In Continued Defense Of Effective Altruism</h1>
    
    <div class="instapaper-info">
        <p><strong>Source:</strong> <a href="https://www.astralcodexten.com/p/in-continued-defense-of-effective">https://www.astralcodexten.com/p/in-continued-defense-of-effective</a></p>
        <p><strong>Folders:</strong> Unread, Archive, Starred</p>
        
    </div>
    
    <div class="content"><p><div><p><strong>I.</strong></p><p>Search “effective altruism” on social media right now, and it’s pretty grim.</p><p>Socialists think we’re sociopathic Randroid money-obsessed Silicon Valley hypercapitalists.</p><p>But Silicon Valley thinks we’re all overregulation-loving authoritarian communist bureaucrats.</p><p>The right thinks we’re all woke SJW extremists. </p><p>But the left thinks we’re all fascist white supremacists.</p><p>The anti-AI people think we’re the PR arm of AI companies, helping hype their products by saying they’re superintelligent at this very moment.</p><p>But the pro-AI people think we want to ban all AI research forever and nationalize all tech companies.</p><p>The hippies think we’re a totalizing ideology so hyper-obsessed with ethics that we never have fun or live normal human lives.</p><p>But the zealots think we’re a grift who only pretend to care about about charity, while we really spend all of our time feasting in castles.</p><p>The bigshots think we’re naive children who fall apart at our first contact with real-world politics.</p><p><span>But the journalists think we’re a sinister conspiracy that has </span><a href="https://www.politico.com/news/2023/10/13/open-philanthropy-funding-ai-policy-00121362">“taken over Washington”</a><span> and have the whole Democratic Party in our pocket.</span></p><div><figure><div><div><picture><img src="https://substackcdn.com/image/fetch/$s_!0pQN!%2Cw_848%2Cc_limit%2Cf_auto%2Cq_auto:good%2Cfl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F786357a9-13d3-43c5-9634-fec40306942f_1994x1978.png"></picture><figcaption>Click to expand. Source: https://twitter.com/the_megabase/status/1728771254336036963</figcaption></div></div></figure></div><p>The only thing everyone agrees on is that the only two things EAs ever did were “endorse SBF” and “bungle the recent OpenAI corporate coup.”</p><p>In other words, there’s never been a better time to become an effective altruist! Get in now, while it’s still unpopular! The times when everyone fawns over us are boring and undignified. It’s only when you’re fighting off the entire world that you feel truly alive.</p><p><span>And I do think the movement is worth fighting for. Here’s a short, very incomplete list of things effective altruism has accomplished in its ~10 years of existence. I’m counting it as an EA accomplishment if EA </span><em>either</em><span> provided the funding </span><em>or</em><span> did the work, further explanations in the footnotes. I’m also slightly conflating EA, rationalism, and AI doomerism rather than doing the hard work of teasing them apart:</span></p><p><em><strong>Global Health And Development</strong></em></p><ul><li><p><span>Saved about 200,000 lives total, mostly from malaria</span><span><a href="https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-1-86909076">1</a></span></p></li><li><p><span>Treated 25 million cases of chronic parasite infection.</span><span><a href="https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-2-86909076">2</a></span></p></li><li><p><span>Given 5 million people access to clean drinking water.</span><span><a href="https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-3-86909076">3</a></span></p></li><li><p><span>Supported clinical trials for both the RTS.S malaria vaccine (currently approved!) and the R21/Matrix malaria vaccine (on track for approval)</span><span><a href="https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-4-86909076">4</a></span></p></li><li><p><span>Supported additional research into vaccines for syphilis, malaria, helminths, and hepatitis C and E.</span><span><a href="https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-5-86909076">5</a></span></p></li><li><p><span>Supported teams giving development economics advice in Ethiopia, India, Rwanda, and around the world.</span><span><a href="https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-6-86909076">6</a></span></p></li></ul><p><em><strong>Animal Welfare:</strong></em></p><ul><li><p><span>Convinced farms to switch 400 million chickens from caged to cage-free.</span><span><a href="https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-7-86909076">7</a></span></p><div><figure><div><div><picture><img src="https://substackcdn.com/image/fetch/$s_!BbuG!%2Cw_932%2Cc_limit%2Cf_auto%2Cq_auto:good%2Cfl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9df72b3f-fbd3-4482-9ea7-041fb5a6d38e_920x520.webp"></picture><figcaption>Things are now slightly better than this in some places! Source: https://www.vox.com/future-perfect/23724740/tyson-chicken-free-range-humanewashing-investigation-animal-cruelty</figcaption></div></div></figure></div></li><li><p><span>Freed 500,000 pigs from tiny crates where they weren’t able to move around</span><span><a href="https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-8-86909076">8</a></span></p></li><li><p>Gotten 3,000 companies including Pepsi, Kelloggs, CVS, and Whole Foods to commit to selling low-cruelty meat.</p></li></ul><p><em><strong>AI:</strong><span> </span></em></p><ul><li><p><span>Developed </span><a href="https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback">RLHF</a><span>, a technique for controlling AI output widely considered the key breakthrough behind ChatGPT.</span><span><a href="https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-9-86909076">9</a></span></p></li><li><p><span>…and other major AI safety advances, including </span><a href="https://www.astralcodexten.com/p/constitutional-ai-rlhf-on-steroids">RLAIF</a><span> and the foundations of AI interpretability</span><span><a href="https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-10-86909076">10</a></span><span>.</span></p></li><li><p><span>Founded the field of AI safety, and incubated it from nothing up to the point where Geoffrey Hinton, Yoshua Bengio, Demis Hassabis, Sam Altman, Bill Gates, and hundreds of others </span><a href="https://www.safe.ai/statement-on-ai-risk">have endorsed it</a><span> and urged policymakers to take it seriously.</span><span><a href="https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-11-86909076">11</a></span></p></li><li><p><span>Helped convince OpenAI to dedicate 20% of company resources </span><a href="https://openai.com/blog/introducing-superalignment">to a team</a><span> working on aligning future superintelligences.</span></p></li><li><p><span>Gotten major AI companies including OpenAI to work with </span><a href="https://evals.alignment.org/">ARC Evals</a><span> and evaluate their models for dangerous behavior before releasing them.</span></p></li></ul><div><figure><div><div><picture><img src="https://substackcdn.com/image/fetch/$s_!_9jh!%2Cw_1040%2Cc_limit%2Cf_auto%2Cq_auto:good%2Cfl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a810ce3-1e5d-4522-bf79-0f3983edd45d_586x418.png"></picture><figcaption>I don't exactly endorse this Tweet, but it is . . . a thing . . . someone has said.</figcaption></div></div></figure></div><ul><li><p><span>Got two seats on the board of OpenAI, held majority control of OpenAI for one wild weekend, and still apparently might have some seats on the board of OpenAI, somehow?</span><span><a href="https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-12-86909076">12</a></span></p></li><li><p><span>Helped found, and continue to have majority control of, competing AI startup </span><a href="https://www.nytimes.com/2023/07/11/technology/anthropic-ai-claude-chatbot.html">Anthropic</a><span>, a $30 billion company widely considered the only group with technology comparable to OpenAI’s.</span><span><a href="https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-13-86909076">13</a></span><br></p></li></ul><div><figure><div><div><picture><img src="https://substackcdn.com/image/fetch/$s_!yQOf!%2Cw_848%2Cc_limit%2Cf_auto%2Cq_auto:good%2Cfl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8168d6bd-3489-4ed1-8f03-c17ce2374993_594x110.png"></picture><figcaption>I don't exactly endorse and so on.</figcaption></div></div></figure></div><ul><li><p><span>Become so influential in AI-related legislation that Politico accuses effective altruists of having </span><a href="https://www.politico.com/news/2023/10/13/open-philanthropy-funding-ai-policy-00121362">“[taken] over Washington”</a><span> and </span><a href="https://www.politico.eu/article/rishi-sunak-artificial-intelligence-pivot-safety-summit-united-kingdom-silicon-valley-effective-altruism/">“largely dominating the UK’s efforts to regulate advanced AI”</a><span>. </span></p></li><li><p>Helped (probably, I have no secret knowledge) the Biden administration pass what they called "the strongest set of actions any government in the world has ever taken on AI safety, security, and trust.”</p></li><li><p><span>Helped the British government create its </span><a href="https://www.gov.uk/government/publications/frontier-ai-taskforce-first-progress-report/frontier-ai-taskforce-first-progress-report">Frontier AI Taskforce</a><span>.</span></p></li><li><p><span>Won the PR war: </span><a href="https://theaipi.org/poll-shows-overwhelming-concern-about-risks-from-ai-as-new-institute-launches-to-understand-public-opinion-and-advocate-for-responsible-ai-policies/">a recent poll</a><span> shows that 70% of US voters believe that mitigating extinction risk from AI should be a “global priority”.</span></p></li></ul><p><em><strong>Other:</strong></em></p><ul><li><p><span>Helped organize the </span><a href="https://securedna.org/">SecureDNA</a><span> consortium, which helps DNA synthesis companies figure out what their customers are requesting and avoid accidentally selling bioweapons to terrorists</span><span><a href="https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-14-86909076">14</a></span><span>.</span></p></li><li><p><span>Provided a significant fraction of all funding for DC groups trying to lower the risk of nuclear war.</span><span><a href="https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-15-86909076">15</a></span></p></li><li><p><span>Donated </span><a href="https://www.theonion.com/anonymous-philanthropist-donates-200-human-kidneys-to-h-1819594700">a few hundred kidneys</a><span>.</span><span><a href="https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-16-86909076">16</a></span></p></li><li><p><span>Sparked a renaissance in forecasting, including major roles in creating, funding, and/or staffing </span><a href="https://www.metaculus.com/home/">Metaculus</a><span>, </span><a href="https://manifold.markets/home">Manifold Markets</a><span>, and the </span><a href="https://forecastingresearch.org/">Forecasting Research Institute</a><span>.</span></p></li><li><p><a href="https://www.openphilanthropy.org/grants/johns-hopkins-center-for-health-security-biosecurity-global-health-security-and-global-catastrophic-risks-2017/">Donated </a><span>tens of millions of dollars to pandemic preparedness causes years before COVID, and </span><a href="https://twitter.com/Dominic2306/status/1373333437319372804">positively influenced some countries’ COVID policies</a><span>.</span></p></li><li><p><span>Played a big part in creating the YIMBY movement - I’m as surprised by this one as you are, but see footnote for evidence</span><span><a href="https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-17-86909076">17</a></span><span>.</span></p></li></ul><p>I think other people are probably thinking of this as par for the course - all of these seem like the sort of thing a big movement should be able to do. But I remember when EA was three philosophers and few weird Bay Area nerds with a blog. It clawed its way up into the kind of movement that could do these sorts of things by having all the virtues it claims to have: dedication, rationality, and (I think) genuine desire to make the world a better place.</p><p><strong>II.</strong></p><p>Still not impressed? Recently, in the US alone, effective altruists have:</p><ul><li><p>ended all gun violence, including mass shootings and police shootings</p></li><li><p>cured AIDS and melanoma</p></li><li><p>prevented a 9-11 scale terrorist attack</p></li></ul><p>Okay. Fine. EA hasn’t, technically, done any of these things. </p><p><span>But it </span><em>has</em><span> saved the same number of lives that doing all those things would have.</span></p><p><span>About 20,000 Americans die yearly of gun violence, 8,000 of melanoma, 13,000 from AIDS, and 3,000 people in 9/11. So doing all of these things would save 44,000 lives per year. That matches the ~50,000 lives that effective altruist charities save yearly</span><span><a href="https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-18-86909076">18</a></span><span>.</span></p><p><span>People aren’t acting like EA has ended gun violence and cured AIDS and so on. all those things. Probably this is because those are exciting popular causes in the news, and saving people in developing countries isn’t. Most people care so little about saving lives in developing countries that effective altruists can save 200,000 of them and people will just </span><em>not notice</em><span>. “Oh, all your movement ever does is cause corporate boardroom drama, and maybe other things I’m forgetting right now.”</span></p><p><span>In a world where people thought saving 200,000 lives mattered as much as whether you caused boardroom drama, we wouldn’t </span><em>need</em><span> effective altruism. These skewed priorities are the exact problem that effective altruism exists to solve - or the exact inefficiency that effective altruism exists to exploit, if you prefer that framing. Nobody cares about preventing pandemics, everyone cares about whether SBF was in a polycule or not. Effective altruists will only intersect with the parts of the world that other people care about when we screw up; therefore, everyone will think of us as “those guys who are constantly screwing up, and maybe do other things I’m forgetting right now”.</span></p><p><span>And I think the screwups are comparatively minor. Allying with a crypto billionaire who turned out to be a scammer. Being part of a board who fired a CEO, then backpedaled after he threatened to destroy the company. </span><s>These are bad, but I’m not sure they cancel out the effect of saving </s><em><s>one</s></em><s> life, let alone 200,000</s><span> (see #57 </span><a href="https://www.astralcodexten.com/publish/post/5400617">here</a><span>)</span></p><p><span>(Somebody’s going to accuse me of downplaying the FTX disaster here. I agree FTX was genuinely bad, and I feel bad for the people who lost money. But I think this proves my point: in a year of nonstop commentary about how effective altruism sucked and never accomplished anything and should be judged entirely on the FTX scandal, nobody ever accused </span><em>those people</em><span> of downplaying the 200,000 lives saved. The discourse sure does have its priorities.)</span></p><p>Doing things is hard. The more things you do, the more chance that one of your agents goes rogue and you have a scandal. The Democratic Party, the Republican Party, every big company, all major religions, some would say even Sam Altman - they all have past deeds they’re not proud of, or plans that went belly-up. I think EA’s track record of accomplishments vs. scandals is as good as any of them, maybe better. It’s just that in our case, the accomplishments are things nobody except us notices or cares about. Like saving 200,000 lives. Or ending the torture of hundreds of millions of animals. Or preventing future pandemics. Or preparing for superintelligent AI.</p><p><span>But if any of these things do matter to you, you can’t help thinking that all those people on Twitter saying EA has never done anything except lurch from scandal to scandal are morally insane. That’s where I am right now. Effective altruism feels like a tiny precious cluster of people who actually care about whether anyone else lives or dies, in a way unmediated by which newspaper headlines go viral or not. My first, second, and so on to hundredth priorities are protecting this tiny cluster and helping it grow. After that I will grudgingly admit that it sometimes screws up - screws up in a way that is </span><em>nowhere near</em><span> as bad as it’s good to end gun violence and cure AIDS and so - and try to figure out ways to screw up less. But not if it has any risk of killing the goose that lays the golden eggs, or interferes with priorities 1 - 100.</span></p><p><strong>III.</strong></p><p>Am I cheating by bringing up the 200,000 lives too many times?</p><p>People like to say things like “effective altruism is just a bunch of speculative ideas about animal rights and the far future, the stuff about global health is just a distraction”. </p><p><span>If you really believe that, you should be doubly amazed! We managed to cure AIDS and prevent 9/11 and so on </span><em>as a distraction</em><span>, when it wasn’t even the main thing we wanted to be doing! We said “on the way to doing the other things we really care about, let’s stop for a second to cure AIDS and prevent 9/11, it won’t take too much time or resources away from the important stuff”. Why haven’t any of you distraction-free people managed that?</span></p><p>I don’t think any of this is a distraction. The Democratic Party is anti-gun and pro-choice. The gun control isn’t a ruse to trick pro-life people into joining the party, and the abortion rights aren’t a smokescreen to deflect opposition from gun owners. Movements are coalitions. Sometimes this means different people with different priorities choose to work together. But other times it means the same people tend to share both priorities. People who are pro-choice are usually also anti-gun, and vice versa.</p><p>And I notice that the tiny handful of people capable of caring about 200,000 people dying of neglected tropical diseases are the same tiny handful of people capable of caring about the next pandemic, or superintelligence, or human extinction. I think the common skill is trying to analyze what causes are important logically. Surprisingly, this comes up with different results than the usual strategy of caring about whatever is trending on Twitter today! Some of those results are broadly popular, like saving 200,000 lives. Other results are broadly unpopular, like worrying about AI risk. But both sets of results come from the same process, and the people who get them are natural allies in a world where most people can’t bring themselves to care about anything that isn’t current front-page news.</p><div><figure><div><div><picture><img src="https://substackcdn.com/image/fetch/$s_!znna!%2Cw_848%2Cc_limit%2Cf_auto%2Cq_auto:good%2Cfl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb33b0595-025d-4497-be06-0db331ca874e_736x481.png"></picture><figcaption>Which of these is "the thing EAs really do"? Which are the distractions and bait-and-switches? Source: https://forum.effectivealtruism.org/posts/ZbaDmowkXbTBsxvHn/historical-ea-funding-data</figcaption></div></div></figure></div><p><span>I don’t want the takeaway from this post to be “Sure, you may hate EA because it does a lot of work on AI - but come on, it also does a lot of work on global health and poverty!” I’m proud of all of it. I believe - </span><a href="https://archive.is/o/pyNyA/https://www.safe.ai/statement-on-ai-risk">just like</a><span> Geoff Hinton, Bill Gates, Sam Altman, Daniel Dennett, etc - that there’s a pretty serious risk of human extinction from AI over the next few decades. I can’t imagine believing this and not thinking it’s important to prepare for. EA has done a great job working on this (see list of accomplishments above), and I think the AI and x-risk people have just as much to be proud of as the global health and animal welfare people.</span></p><p><span>So my recommendation is that you look carefully into the research on what causes can most benefit the world - near-term, long-term, whatever seems most important to you after some honest study  - and try to come up with some way to help them. If you want, take </span><a href="https://www.givingwhatwecan.org/en-US/pledge">the Giving What We Can pledge</a><span> to donate 10% of your income, or look at </span><a href="https://80000hours.org">80,000 Hours</a><span> to see how you can get an altruistic career.</span></p><p>And whatever you do, do it quick, before the metronome swings back and all of this becomes popular again.</p><div><a href="https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-anchor-1-86909076">1</a><div><p><span>Source: AMF says 185,000 deaths prevented </span><a href="https://forum.effectivealtruism.org/posts/fkft56o8Md2HmjSP7/amf-reflecting-on-2023-and-looking-ahead-to-2024">here</a><span>; GiveWell’s </span><a href="https://www.givewell.org/charities/amf">evaluation</a><span> makes this number sound credible. AMF </span><a href="https://www.againstmalaria.com/financialinformation.aspx">reports</a><span> revenue of $100M/year and GiveWell </span><a href="https://files.givewell.org/files/metrics/GiveWell_Metrics_Report_2021.pdf">reports</a><span> giving them about $90M/year, so I think GiveWell is most of their funding and it makes sense to think of them as primarily an EA project. GiveWell </span><a href="https://forum.effectivealtruism.org/topics/malaria-consortium">estimates</a><span> that Malaria Consortium can prevent one death for $5,000, and EA </span><a href="https://forum.effectivealtruism.org/topics/malaria-consortium">has donated</a><span> $100M/year for (AFAICT) several years, so 20,000 lives/year times some number of years. I have rounded these two sources combined off to 200,000. As a sanity check, malaria death toll declined from about 1,000,000 to 600,000 between 2000 and 2015 mostly because of bednet programs like these, meaning EA-funded donations in their biggest year were responsible for about 10% of the yearly decline. This doesn’t seem crazy to me given the scale of EA funding compared against all malaria funding.</span></p></div></div><div><a href="https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-anchor-2-86909076">2</a><div><p><span>Source: </span><a href="https://forum.effectivealtruism.org/topics/sci-foundation">this page</a><span> says about $1 to deworm a child. There are about $50 million worth of grants recorded </span><a href="https://www.openphilanthropy.org/grants/?q=schistosomiasis&amp;sort=high-to-low#categories">here</a><span>, and I’m arbitrarily subtracting half for overhead. As a sanity check, Unlimit Health, a major charity in this field, </span><a href="https://unlimithealth.org/about/our-impact/">says it dewormed</a><span> 39 million people last year (though not necessarily all with EA funding). I think the number I gave above is probably an underestimate. The exact effects of deworming are controversial, see </span><a href="https://www.vox.com/2015/7/24/9031909/worm-wars-explained">this link</a><span> for more. Most of the money above went to deworming for schistosomiasis, which might work differently than other parasites. See GiveWell’s analysis </span><a href="https://www.givewell.org/charities/sci-foundation/November-2021-version">here</a><span>.</span></p></div></div><div><a href="https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-anchor-3-86909076">3</a><div><p><span>Source: </span><a href="https://blog.givewell.org/2022/10/14/answering-questions-about-water-quality-programs/">this page</a><span>. See “Evidence Action says Dispensers for Safe Water is currently reaching four million people in Kenya, Malawi, and Uganda, and this grant will allow them to expand that to 9.5 million.” Cf </span><a href="https://www.evidenceaction.org/programs/safe-water-now">the charity’s website</a><span>, which says it costs $1.50 per person/year. GiveWell’s grant is for $64 million, which would check out if the dispensers were expected to last ~10 years.</span></p></div></div><div><a href="https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-anchor-4-86909076">4</a><div><p><span>RTS,S sources </span><a href="https://www.givewell.org/research/grants/PATH-malaria-vaccines-January-2022">here</a><span> and </span><a href="https://blog.givewell.org/2023/05/12/why-givewell-funded-malaria-vaccine-rollout/">here</a><span>; R21 source </span><a href="https://www.openphilanthropy.org/grants/institut-de-recherche-en-sciences-de-la-sante-malaria-vaccine-clinical-trial-halidou-tinto/">here</a><span>; given </span><a href="https://en.wikipedia.org/wiki/Halidou_Tinto">this page</a><span> I think it is about R21.</span></p></div></div><div><a href="https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-anchor-5-86909076">5</a><div><p><span>See </span><a href="https://www.openphilanthropy.org/grants/?q=vaccine">here</a><span>. I have no idea whether any of this research did, or will ever, pay off.</span></p></div></div><div><a href="https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-anchor-6-86909076">6</a><div><p><span>Ethiopia source </span><a href="https://www.openphilanthropy.org/grants/innovations-for-poverty-action-ethiopian-office/">here </a><span>and </span><a href="https://www.openphilanthropy.org/grants/new-york-university-ethiopia-urban-expansion-initiative-follow-up/">here</a><span>, India source </span><a href="https://www.openphilanthropy.org/grants/peterson-institute-for-international-economics-indian-economic-policy-reform/">here</a><span>, Rwanda source </span><a href="https://www.growth-teams.org/who-we-are">here</a><span>.</span></p></div></div><div><a href="https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-anchor-7-86909076">7</a><div><p><span>Estimate for number of chickens </span><a href="https://rethinkpriorities.org/publications/corporate-campaigns-affect-9-to-120-years-of-chicken-life-per-dollar-spent">here</a><span>. Their numbers add up to 800 million but I am giving EA half-credit because not all organizations involved were EA-affiliated. I’m counting groups like Humane League, Compassion In World Farming, Mercy For Animals, etc as broadly EA-affiliated, and I think it’s generally agreed they’ve been the leaders in these sorts of campaigns. </span></p></div></div><div><a href="https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-anchor-8-86909076">8</a><div><p><span>Discussion </span><a href="https://www.openphilanthropy.org/research/a-big-supreme-court-win-for-farm-animals/">here</a><span>. That link says 700,000 pigs; </span><a href="https://www.thepigsite.com/news/2023/05/prop-12">this one</a><span> says 300,000 - 500,000; I have compromised at 500,000. Open Phil </span><a href="https://ballotpedia.org/California_Proposition_12,_Farm_Animal_Confinement_Initiative_(2018)">was the biggest single donor </a><span>to Prop 12. </span></p></div></div><div><a href="https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-anchor-9-86909076">9</a><div><p><a href="https://arxiv.org/abs/1706.03741">The original RLHF paper</a><span> was written by OpenAI’s safety team. At least two of the six authors, including lead author Paul Christiano, are self-identified effective altruists (maybe more, I’m not sure), and the original human feedbackers were random volunteers Paul got from the rationalist and effective altruist communities.</span></p></div></div><div><a href="https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-anchor-10-86909076">10</a><div><p>I recognize at least eight of the authors of the RLAIF paper as EAs, and four members of the interpretability team, including team lead Chris Olah. Overall I think Anthropic’s safety team is pretty EA focused.</p></div></div><div><a href="https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-anchor-12-86909076">12</a><div><p>Open Philanthropy Project originally got one seat on the OpenAI board by supporting them when they were still a nonprofit; that later went to Helen Toner. I’m not sure how Tasha McCauley got her seat. Currently the provisional board is Bret Taylor, Adam D’Angelo, and Larry Summers. Summers says he “believe[s] in effective altruism” but doesn’t seem AI-risk-pilled. Adam D’Angelo has never explicitly identified with EA or the AI risk movement but seems to have sided with the EAs in the recent fight so I’m not sure how to count him.</p></div></div><div><a href="https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-anchor-13-86909076">13</a><div><p><span>The founders of Anthropic included several EAs (I can’t tell if CEO Dario Amodei is an EA or not). The original investors included Dustin Moskowitz, Sam Bankman-Fried, Jaan Tallinn, and various EA organizations. Its Wikipedia article says that “Journalists often connect Anthropic with the effective altruism movement”. Anthropic is controlled by a </span><a href="https://www.anthropic.com/index/the-long-term-benefit-trust">board of trustees</a><span>, most of whose members are effective altruists.</span></p></div></div><div><a href="https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-anchor-14-86909076">14</a><div><p><span>See </span><a href="https://securedna.org/features/">here</a><span>, Open Philanthropy is first-listed funder. Leader Kevin Esvelt has spoken at </span><a href="https://www.effectivealtruism.org/articles/kevin-esvelt-mitigating-catastrophic-biorisks">EA Global conferences</a><span> and on </span><a href="https://80000hours.org/podcast/episodes/kevin-esvelt-stealth-wildfire-pandemics/">80,000 Hours</a></p></div></div><div><a href="https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-anchor-15-86909076">15</a><div><p><span>Total private funding for nuclear strategy </span><a href="https://www.vox.com/2022/3/17/22976981/nuclear-war-russia-ukraine-funding-macarthur-existential-risk-effective-altruism-carnegie">is $40 million</a><span>. Longview Philanthropy has a </span><a href="https://www.longview.org/fund/nuclear-weapons-policy-fund/">nuclear policy fund</a><span> with two managers, which suggests they must be doing enough granting to justify their salaries, probably something in the seven digits. Council on Strategic Risks </span><a href="https://councilonstrategicrisks.org/2022/03/17/csr-receives-major-grant-to-address-the-rising-risks-of-nuclear-conflict/">says</a><span> Longview gave them a $1.6 million grant, which backs up “somewhere in the seven digits”. Seven digits would mean somewhere between 2.5% and 25% of all nuclear policy funding.</span></p></div></div><div><a href="https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-anchor-16-86909076">16</a><div><p><span>I admit this one is a wild guess. I know about 5 EAs who have donated a kidney, but I don’t know anywhere close to all EAs. Dylan Matthews says his article inspired between a dozen and a few dozen donations. The staff at the hospital where I donated my kidney seemed well aware of EA and not surprised to hear it was among my reasons for donating, which suggests they get EA donors regularly. There were about 400 nondirected kidney donations in the US per year </span><a href="https://www.sciencedirect.com/science/article/pii/S2468024922012311">in 2019</a><span>, but that number is growing rapidly. Since EA was founded in the early 2010s, there have probably been a total of ~5000. I think it’s reasonable to guess EAs have been between 5 - 10% of those, leading to my estimate of hundreds. </span></p></div></div><div><a href="https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-anchor-17-86909076">17</a><div><p><a href="https://en.wikipedia.org/wiki/Open_Philanthropy">Open Philanthropy’s Wikipedia page</a><span> says it was “the first institutional funder for the YIMBY movement”. The Inside Philanthropy website </span><a href="https://www.insidephilanthropy.com/home/2022/7/21/what-is-yimbyism-and-why-arent-more-funders-paying-attention">says</a><span> that “on the national level, Open Philanthropy is one of the few major grantmakers that has offered the YIMBY movement full-throated support.” Open Phil started giving money to YIMBY causes in 2015, and has donated about $5 million, a significant fraction of its total funding.</span></p></div></div><div><a href="https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-anchor-18-86909076">18</a><div><p>Above I say about 200,000 lives total, but that’s heavily skewed towards recently since the movement has been growing. I got the 50,000 lives number by GiveWell’s total money moved for last year divided by cost-effectiveness, but I think it matches well with the 200,000 number above.</p></div></div></div></p></div>
</body>
</html>