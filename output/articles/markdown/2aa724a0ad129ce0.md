# The loops that AI enables, and why your kids will be smarter than you

**Source:** [https://think.ryi.me/p/the-loops-that-ai-enables-and-why](https://think.ryi.me/p/the-loops-that-ai-enables-and-why)  
**Folders:** Unread, Archive, Starred  

---

<div><p><strong>I think the world is too focused on the particular capabilities of LLMs without considering the new behaviors they enable</strong><span>. One aspect of this is as follows: knowledge acquisition is the rate-limiting step in nearly all human endeavors, and LLMs dismantle this barrier by acting as knowledge interpolation machines.</span></p><p>To see why this is, consider what happens when you want to learn to do something new, make a decision, take an action. You can only start after acquiring the requisite knowledge. Want to build a house? You need to learn how to build a house. Want to build a new product feature? You need to learn more about the market first. Want to learn to skateboard? You get the idea.</p><p><span>But LLMs represent a paradigm shift here. LLMs let you answer basically any question you have. Need to do something? You no longer need a person or do a stupid amount of research to unblock you — you can just ask an LLM. As a result, any process rate-limited by knowledge (basically, </span><em>any</em><span> process) can fill in knowledge gaps with answers from an LLM. </span></p><div><figure><a href="https://substackcdn.com/image/fetch/$s_!loIq!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F499c51bc-4cc2-4b73-ac9d-a2ca5a662f67_1024x1024.png"><div><picture><img src="https://substackcdn.com/image/fetch/$s_!loIq!%2Cw_848%2Cc_limit%2Cf_auto%2Cq_auto:good%2Cfl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F499c51bc-4cc2-4b73-ac9d-a2ca5a662f67_1024x1024.png"></picture></div></a></figure></div><p><span>Traditionally, though, the world has been thinking about how this can fit into our world as-is. </span><strong>But the exciting thing about this is not that it simply makes existing behaviors faster, but that it enables new behaviors altogether.</strong></p><p><span>To make this concrete, I’m going to talk about what I find to be a particularly compelling application of LLMs: </span><strong>learning</strong><span> (and… it also happens to be the one most obviously rate-limited by knowledge acquisition).</span></p><h1>How LLMs make learning better</h1><h3>We were raised by textbooks, but people are better.</h3><p>Historically (pre-LLM), whenever I’ve wanted to learn something, I would instinctively reach for textbooks and courses. There’s nothing quite as satisfying as turning to page 1 and shoehorning information into your brain. When I’d get stuck on a particularly concept, I’d turn to Google, Wikipedia, Youtube videos to fill in the gaps — alone, of course, these systems were never so reliable a source that you could rely on them to attain a comprehensive understanding of a subject, but they were strong support vectors. But this whole process was long, arduous, and only tenable for the academically inclined.</p><p><span>And in that world, the best alternatives for faster knowledge ingestion were </span><em>people</em><span> — learning from a person 1-1 allows you to unblock your thinking faster than any textbook possibly can. This was the beauty of education systems: [assuming you leveraged your school’s resources in this way,] you could present your learning blockers to another person, and they’d unblock you directly. I probably attended more office hours + problem set nights than lectures during my undergraduate years, and this was precisely why.</span></p><h3>But LLMs are more efficient than people.</h3><p><span>LLMs offer us a lower-friction alternative to people. Just as with other people, with LLMs, you get </span><em>coverage</em><span>. Nearly every question you have will be answered. Not with perfect accuracy, of course, but with enough proximity to truth that you can navigate a space in which you would otherwise have much slower pathing through — the LLM is the pedagogical equivalent of a GPS, where we only had people, paper maps, and exhaustively driving around as mechanisms before. You can navigate to unblocking answers faster — much more expediently than waiting to ask a person, with more reliability than Google, and with greater efficiency than taking a course.</span></p><div><figure><a href="https://substackcdn.com/image/fetch/$s_!VBU-!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7a80c9b-0644-4d95-a2f5-a2c476e95d55_2670x1106.png"><div><picture><img src="https://substackcdn.com/image/fetch/$s_!VBU-!%2Cw_848%2Cc_limit%2Cf_auto%2Cq_auto:good%2Cfl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7a80c9b-0644-4d95-a2f5-a2c476e95d55_2670x1106.png"></picture></div></a></figure></div><h3>And the great benefit: this encourages curiosity loops.</h3><p><span>If faster pathing to your desired answer was the only benefit, LLMs would be a marginal improvement. But the chief, more profound repercussion of LLMs is that they enable you to learn in a fundamentally different way: you don't just get to your answers faster, but you can take different paths through subject matter. In particular, </span><strong>you can follow curiosity-led pathways</strong><span>.</span></p><p><span>Other media is inherently structured according to another person’s curiosity chain or what they believe your curiosity chain ought to be. As a result, textbooks/courses/etc. are rarely nicely catered to your own brain. LLMs, on the other hand, allow you to naturally fit information to the natural flow of your own questions. And these curiosity loops are simply </span><em>better</em><span> than learning pathways built without curiosity. Knowledge acquired through curiosity is generally </span><a href="https://www.scientificamerican.com/article/curiosity-prepares-the-brain-for-better-learning/">better retained, better understood</a><span>. This is a </span><strong>new loop enabled by the LLM</strong><span>.</span></p><p>This is the opportunity kids growing up with LLMs will have, and I find this so exciting. Look at the following chain of questions my 4-year-old recently asked ChatGPT, and you’ll immediately see how fundamentally different this is from a normal conversation with an adult:</p><blockquote><p><em><strong>E:</strong><span> “How do beavers not get splinters?”</span></em><br><strong>ChatGPT [paraphrased]:</strong><span> They have thick fur and skin.</span></p><p><em><strong>E:</strong><span> “How does beavers fur stay on?”</span></em><br><strong>C:</strong><span> It’s like how your hair sticks on your head. Fur goes through tiny holes in the skin, and it’s snug, so it doesn’t fall out easily.</span></p><p><em><strong>E:</strong><span> “How do walruses’ tusks stay on?”</span></em><br><strong>C:</strong><span> It’s similar to how teeth stay in our mouths. Here’s a simple way to understand it…</span></p><p><em><strong>E:</strong><span> “Why are there not regular dogs or pups?”</span><br></em><strong>C:</strong><span> Can you clarify?</span><br><em><strong>Me (Dad):</strong><span> “Yes, she was asking why there isn’t a standard dog, why do all dogs look different?”</span></em><br><strong>C:</strong><span> Oh I see! Tell her that dogs look different because they come from different places and were bred for different jobs. That’s why we have many different types of dogs, and why there isn’t one standard dog. Each dog is special in its own way.</span></p><p><em><strong>E:</strong><span> “Why do otters not have ears?”</span></em><br><strong>C:</strong><span> They do have ears! They might look small and hard to see, especially when they’re in the water.</span></p><p><em><strong>E:</strong><span> “I don’t see any ears up there.”</span></em><br><strong>C:</strong><span> I understand it might be hard to spot their ears. But if you look closely, you might be able to see their little ears sticking out just a bit. They’re always there, just not easy to spot.</span></p><p><em><strong>E:</strong><span> “How do trees stay up?”</span><br><strong>E:</strong><span> “How do birds grow their wings?”</span><br><strong>E:</strong><span> “Where does yarn come from?”</span><br><strong>E:</strong><span> “How do birds fly?”</span><br><strong>E:</strong><span> “Where do socks come from?”</span><br><strong>E:</strong><span> “Where do chairs come from?”</span><br><strong>E:</strong><span> “Plastic is made of oil!?”</span><br><strong>E:</strong><span> “What are phones made of?”</span><br><strong>E:</strong><span> “Do you think phones are made of gold and copper too?”</span><br><strong>E:</strong><span> “How do phones do all these things?”</span><br><strong>E:</strong><span> “Want me to show you a picture of something?”</span></em></p></blockquote><p>My answers would have paled in comparison — they’d be immediately biased by my own framing, riddled with concepts too advanced for a 4 year old, and, while not my intent, immediately curiosity-breaking. But LLMs, on the other hand, have a breadth of knowledge, speed of delivery, and concision that a person just can’t compete with. For once, there exists a system that’s able to convey ideas at the rate and level of nuance at which a child wants to ingest them.</p><h1>Final comments</h1><p>And so your kids will likely be smarter than you, in many ways — at least from the perspective of having access to unprecedentedly expeditious knowledge interpolation systems. Practically speaking, though, this is something we all ought to take advantage of immediately. I’ve personally found it much faster to learn about a subject by using an LLM to ask questions about it, rather than taking a course or trying to read through documentation (or better yet, throw a textbook/documentation at the LLM).</p><p><span>But a broader comment here: this is one, particularly compelling loop born of LLMs, but consider how often you’re blocked by knowledge — companies are often rate-limited by alignment; engineering work is rate-limited by your understanding of a codebase or knowledge of design patterns and libraries; even the entire data industry is about disseminating knowledge locked in data more efficiently. There are certainly existing pathways that can be made more efficient through integration of LLMs, but consider what pathways are yet to be discovered that have been, until now, impossible. AI companies springing up should keep this in mind (including our </span><a href="https://titanium.tech">own</a><span>, of course), as the tremendous opportunity comes not from what AI can do, but what we new behaviors are now enabled because of AI. </span></p><div><div><div><p>Thanks for reading Think Better! Subscribe for free to receive new posts and support my work.</p></div></div></div></div>